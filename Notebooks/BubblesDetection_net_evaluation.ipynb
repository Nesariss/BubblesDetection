{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D1d01VGSLNHz"
   },
   "source": [
    "# Loading libs & repos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "E6EC1aRfYq5k",
    "outputId": "4378ffbf-5ace-4487-d847-2e179a2cbe03"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/gdrive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I9Ti_jQfYsjR",
    "outputId": "9ebdb4e2-5c1b-43d5-a625-41a21b1e4e3c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyyaml==5.1\n",
      "  Downloading PyYAML-5.1.tar.gz (274 kB)\n",
      "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/274.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.4/274.2 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m274.2/274.2 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "  \n",
      "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py egg_info\u001b[0m did not run successfully.\n",
      "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "  \u001b[31m╰─>\u001b[0m See above for output.\n",
      "  \n",
      "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25herror\n",
      "\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n",
      "\n",
      "\u001b[31m×\u001b[0m Encountered error while generating package metadata.\n",
      "\u001b[31m╰─>\u001b[0m See above for output.\n",
      "\n",
      "\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n",
      "\u001b[1;36mhint\u001b[0m: See above for details.\n",
      "Collecting git+https://github.com/facebookresearch/detectron2.git\n",
      "  Cloning https://github.com/facebookresearch/detectron2.git to /tmp/pip-req-build-0turpk94\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/facebookresearch/detectron2.git /tmp/pip-req-build-0turpk94\n",
      "  Resolved https://github.com/facebookresearch/detectron2.git to commit 8c4a333ceb8df05348759443d0206302485890e0\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: Pillow>=7.1 in /usr/local/lib/python3.10/dist-packages (from detectron2==0.6) (9.4.0)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from detectron2==0.6) (3.7.1)\n",
      "Requirement already satisfied: pycocotools>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from detectron2==0.6) (2.0.7)\n",
      "Requirement already satisfied: termcolor>=1.1 in /usr/local/lib/python3.10/dist-packages (from detectron2==0.6) (2.3.0)\n",
      "Collecting yacs>=0.1.8 (from detectron2==0.6)\n",
      "  Downloading yacs-0.1.8-py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (from detectron2==0.6) (0.9.0)\n",
      "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from detectron2==0.6) (2.2.1)\n",
      "Requirement already satisfied: tqdm>4.29.0 in /usr/local/lib/python3.10/dist-packages (from detectron2==0.6) (4.66.1)\n",
      "Requirement already satisfied: tensorboard in /usr/local/lib/python3.10/dist-packages (from detectron2==0.6) (2.13.0)\n",
      "Collecting fvcore<0.1.6,>=0.1.5 (from detectron2==0.6)\n",
      "  Downloading fvcore-0.1.5.post20221221.tar.gz (50 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.2/50.2 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Collecting iopath<0.1.10,>=0.1.7 (from detectron2==0.6)\n",
      "  Downloading iopath-0.1.9-py3-none-any.whl (27 kB)\n",
      "Collecting omegaconf<2.4,>=2.1 (from detectron2==0.6)\n",
      "  Downloading omegaconf-2.3.0-py3-none-any.whl (79 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.5/79.5 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting hydra-core>=1.1 (from detectron2==0.6)\n",
      "  Downloading hydra_core-1.3.2-py3-none-any.whl (154 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.5/154.5 kB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting black (from detectron2==0.6)\n",
      "  Downloading black-23.9.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m34.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from detectron2==0.6) (23.1)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from fvcore<0.1.6,>=0.1.5->detectron2==0.6) (1.23.5)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from fvcore<0.1.6,>=0.1.5->detectron2==0.6) (6.0.1)\n",
      "Collecting antlr4-python3-runtime==4.9.* (from hydra-core>=1.1->detectron2==0.6)\n",
      "  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.0/117.0 kB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Collecting portalocker (from iopath<0.1.10,>=0.1.7->detectron2==0.6)\n",
      "  Downloading portalocker-2.8.2-py3-none-any.whl (17 kB)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->detectron2==0.6) (1.1.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->detectron2==0.6) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->detectron2==0.6) (4.42.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->detectron2==0.6) (1.4.5)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->detectron2==0.6) (3.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->detectron2==0.6) (2.8.2)\n",
      "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from black->detectron2==0.6) (8.1.7)\n",
      "Collecting mypy-extensions>=0.4.3 (from black->detectron2==0.6)\n",
      "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
      "Collecting pathspec>=0.9.0 (from black->detectron2==0.6)\n",
      "  Downloading pathspec-0.11.2-py3-none-any.whl (29 kB)\n",
      "Requirement already satisfied: platformdirs>=2 in /usr/local/lib/python3.10/dist-packages (from black->detectron2==0.6) (3.10.0)\n",
      "Requirement already satisfied: tomli>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from black->detectron2==0.6) (2.0.1)\n",
      "Requirement already satisfied: typing-extensions>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from black->detectron2==0.6) (4.5.0)\n",
      "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2==0.6) (1.4.0)\n",
      "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2==0.6) (1.57.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2==0.6) (2.17.3)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2==0.6) (1.0.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2==0.6) (3.4.4)\n",
      "Requirement already satisfied: protobuf>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2==0.6) (3.20.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2==0.6) (2.31.0)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2==0.6) (67.7.2)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2==0.6) (0.7.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2==0.6) (2.3.7)\n",
      "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2==0.6) (0.41.2)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->detectron2==0.6) (5.3.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->detectron2==0.6) (0.3.0)\n",
      "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->detectron2==0.6) (1.16.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->detectron2==0.6) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard->detectron2==0.6) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2==0.6) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2==0.6) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2==0.6) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2==0.6) (2023.7.22)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard->detectron2==0.6) (2.1.3)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->detectron2==0.6) (0.5.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard->detectron2==0.6) (3.2.2)\n",
      "Building wheels for collected packages: detectron2, fvcore, antlr4-python3-runtime\n",
      "  Building wheel for detectron2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for detectron2: filename=detectron2-0.6-cp310-cp310-linux_x86_64.whl size=5738743 sha256=d858864516dd9491fb64b5fa5fa7101581dbf5d151f011d111213fce2b255966\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-itvzheef/wheels/47/e5/15/94c80df2ba85500c5d76599cc307c0a7079d0e221bb6fc4375\n",
      "  Building wheel for fvcore (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for fvcore: filename=fvcore-0.1.5.post20221221-py3-none-any.whl size=61400 sha256=80d5670f392cfd7a031a9600fc14d4c900ba2885dfa2f32a0e802352b9d8f08d\n",
      "  Stored in directory: /root/.cache/pip/wheels/01/c0/af/77c1cf53a1be9e42a52b48e5af2169d40ec2e89f7362489dd0\n",
      "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144554 sha256=79b6406e9f88cb4be2717d1410198c041004e007257fcd00e229bb90cae5b816\n",
      "  Stored in directory: /root/.cache/pip/wheels/12/93/dd/1f6a127edc45659556564c5730f6d4e300888f4bca2d4c5a88\n",
      "Successfully built detectron2 fvcore antlr4-python3-runtime\n",
      "Installing collected packages: antlr4-python3-runtime, yacs, portalocker, pathspec, omegaconf, mypy-extensions, iopath, hydra-core, black, fvcore, detectron2\n",
      "Successfully installed antlr4-python3-runtime-4.9.3 black-23.9.1 detectron2-0.6 fvcore-0.1.5.post20221221 hydra-core-1.3.2 iopath-0.1.9 mypy-extensions-1.0.0 omegaconf-2.3.0 pathspec-0.11.2 portalocker-2.8.2 yacs-0.1.8\n"
     ]
    }
   ],
   "source": [
    "!python -m pip install pyyaml==5.1\n",
    "!python -m pip install 'git+https://github.com/facebookresearch/detectron2.git'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4YxXLwlsYuiR"
   },
   "outputs": [],
   "source": [
    "from detectron2.utils.logger import setup_logger\n",
    "\n",
    "setup_logger()\n",
    "\n",
    "# import some common libraries\n",
    "import numpy as np\n",
    "import os, json, cv2, random\n",
    "from google.colab.patches import cv2_imshow\n",
    "\n",
    "# import some common detectron2 utilities\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.data import MetadataCatalog, DatasetCatalog\n",
    "from detectron2.evaluation import DatasetEvaluator\n",
    "from detectron2.data.datasets import register_coco_instances\n",
    "from PIL import Image\n",
    "import os\n",
    "import torch\n",
    "import cv2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lOB2QyfoLbMz"
   },
   "source": [
    "# Metrics UTILS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fmDWVnV1Lix-"
   },
   "source": [
    "GET BBOX DATA\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N9sk8xA5LdfQ"
   },
   "outputs": [],
   "source": [
    "def get_image_id(json_file, image_name):\n",
    "  for image_entry in json_file[\"images\"]:\n",
    "    if image_entry[\"file_name\"] == image_name:\n",
    "      return image_entry[\"id\"]\n",
    "  return -1\n",
    "\n",
    "def convert_json_bbox(bbox_data):\n",
    "  converted_bbox_data = []\n",
    "  for bbox in bbox_data:\n",
    "    converted_bbox_data.append(\n",
    "        (bbox[0], bbox[1], bbox[0] + bbox[2], bbox[1] + bbox[3])\n",
    "    )\n",
    "  return converted_bbox_data\n",
    "\n",
    "def load_bbox_data(json_file_path, image_name):\n",
    "  coco_json_bbox_data = []\n",
    "  with open(json_file_path, \"r\") as read_file:\n",
    "    json_file = json.load(read_file)\n",
    "  image_id = get_image_id(json_file, image_name)\n",
    "  if image_id >= 0:\n",
    "    for annotation in json_file[\"annotations\"]:\n",
    "      if annotation[\"image_id\"] == image_id:\n",
    "        coco_json_bbox_data.append(tuple(annotation[\"bbox\"]))\n",
    "  # returns data converted from coco json format\n",
    "  return convert_json_bbox(coco_json_bbox_data)\n",
    "\n",
    "def IOU(boxA, boxB):\n",
    "    xA = max(boxA[0], boxB[0])\n",
    "    yA = max(boxA[1], boxB[1])\n",
    "    xB = min(boxA[2], boxB[2])\n",
    "    yB = min(boxA[3], boxB[3])\n",
    "\n",
    "    interArea = abs(max((xB - xA, 0)) * max((yB - yA), 0))\n",
    "    if interArea == 0:\n",
    "        return 0\n",
    "    boxAArea = abs((boxA[2] - boxA[0]) * (boxA[3] - boxA[1]))\n",
    "    boxBArea = abs((boxB[2] - boxB[0]) * (boxB[3] - boxB[1]))\n",
    "    iou = interArea / float(boxAArea + boxBArea - interArea)\n",
    "\n",
    "    return iou\n",
    "\n",
    "def calculate_metrics(ground_truth, prediction_data):\n",
    "    IOUs = []\n",
    "    true_positive = 0 # correct detection\n",
    "    false_positive = 0 # incorrect detection\n",
    "    false_negative = 0 # missing values\n",
    "\n",
    "    true_positive_treshold = 0.6\n",
    "    false_positive_treshold = 0.6\n",
    "\n",
    "    for true_bbox in ground_truth:\n",
    "        max_iou = 0\n",
    "        for pred_bbox in prediction_data:\n",
    "            iou = IOU(true_bbox, pred_bbox)\n",
    "            max_iou = max(iou, max_iou)\n",
    "        if max_iou >= true_positive_treshold:\n",
    "            true_positive += 1\n",
    "            IOUs.append(max_iou)\n",
    "        else:\n",
    "            false_negative += 1\n",
    "            IOUs.append(0)\n",
    "\n",
    "    for pred_box in prediction_data:\n",
    "        max_iou = 0\n",
    "        for true_bbox in ground_truth:\n",
    "            iou = IOU(pred_box, true_bbox)\n",
    "            max_iou = max(iou, max_iou)\n",
    "        if max_iou <= false_positive_treshold:\n",
    "            false_positive += 1\n",
    "    precision = float(true_positive) / (true_positive + false_positive) if (true_positive + false_positive) > 0. else 0.\n",
    "    recall = float(true_positive) / (true_positive + false_negative) if (true_positive + false_negative) > 0. else 0.\n",
    "    f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0. else 0\n",
    "    mean_iou = sum(IOUs) / len(IOUs)\n",
    "\n",
    "    return mean_iou, precision, recall, f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NRiB1ey_Me83"
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vwZYvtcX9_s0"
   },
   "outputs": [],
   "source": [
    "DRIVE_PATH = \"/content/gdrive/MyDrive/magisterka\"\n",
    "MODELS_PATH = os.path.join(DRIVE_PATH, \"models\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5fpi_cGfbabI",
    "outputId": "7200f1f6-e506-497e-aec9-2b2fee2293c1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clear_faster.pth  rcnn_rotate.pth\tRetina_only_rotate.pth\n",
      "model_final.pth   rcnn_saturation.pth\tRetina_saturation.pth\n",
      "rcnn_augment.pth  Retina_augmented.pth\n",
      "rcnn.pth\t  RetinaNet50.pth\n"
     ]
    }
   ],
   "source": [
    "!ls $MODELS_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 401
    },
    "id": "vNQSTuP3MkfM",
    "outputId": "2cf6b702-b532-4915-b77e-0c160adcfa2f"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "errorDetails": {
      "actions": [
       {
        "action": "open_url",
        "actionText": "Open Examples",
        "url": "/notebooks/snippets/importing_libraries.ipynb"
       }
      ]
     },
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-c5b671a3c970>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mdetectron2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_cfg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdetectron2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDefaultPredictor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdetectron2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmodel_zoo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'detectron2'",
      "",
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from detectron2.config import get_cfg\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2 import model_zoo\n",
    "\n",
    "\n",
    "MODEL_DETECTRON2_PATH = os.path.join(MODELS_PATH, \"clear_faster.pth\")\n",
    "PREDICTION_THRESHOLD_DETECTRON = 0.7\n",
    "\n",
    "\n",
    "class Detectron2Model:\n",
    "    \"\"\"Detectron2 model for object detection.\"\"\"\n",
    "\n",
    "    def __init__(self, model_path=MODEL_DETECTRON2_PATH, threshold = PREDICTION_THRESHOLD_DETECTRON, **kwargs):\n",
    "        self.model_path = model_path\n",
    "        self.threshold = threshold\n",
    "        self.cfg = self.get_model_config(model_path=self.model_path, **kwargs)\n",
    "        self.model = self.get_model(model_config=self.cfg)\n",
    "        self.model.training = False\n",
    "\n",
    "    def get_model_config(\n",
    "        self,\n",
    "        model_path,\n",
    "        num_classes=2,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        self.cfg = get_cfg()\n",
    "        self.cfg.MODEL.DEVICE = \"cpu\"\n",
    "        self.cfg.merge_from_file(\n",
    "            model_zoo.get_config_file(\n",
    "\n",
    "              #  \"COCO-Detection/retinanet_R_50_FPN_1x.yaml\"\n",
    "               \"COCO-Detection/faster_rcnn_R_101_FPN_3x.yaml\"\n",
    "            )\n",
    "        )\n",
    "        # \"COCO-Detection/faster_rcnn_X_101_32x8d_FPN_3x.yaml\"\n",
    "\n",
    "        self.cfg.MODEL.WEIGHTS = model_path\n",
    "        self.cfg.MODEL.ROI_HEADS.SCORE_TRESH_TEST = self.threshold\n",
    "        self.cfg.MODEL.ROI_HEADS.NUM_CLASSES = num_classes\n",
    "       # self.cfg.MODEL.RETINANET.NUM_CLASSES=2\n",
    "        return self.cfg\n",
    "\n",
    "    def set_trainer(self, trainer):\n",
    "        self.trainer = trainer\n",
    "\n",
    "    def get_model(self, model_config):\n",
    "        predictor = DefaultPredictor(model_config)\n",
    "        return predictor\n",
    "\n",
    "    def get_evaluator(self, dataset):\n",
    "        evaluator = COCOEvaluator(dataset, cfg, False, output_dir=\"./output/\")\n",
    "        return evaluator\n",
    "\n",
    "    def set_threshold(self, threshold):\n",
    "        self.cfg.MODEL.ROI_HEADS.SCORE_TRESH_TEST = threshold\n",
    "\n",
    "    def get_threshold(self):\n",
    "        return self.cfg.MODEL.ROI_HEADS.SCORE_TRESH_TEST\n",
    "\n",
    "    def predict(self, image, threshold = 0.85):\n",
    "        prediction = self.model(image)\n",
    "        prediction_bboxes = self.__get_bbox_data(prediction, threshold)\n",
    "        return prediction_bboxes\n",
    "\n",
    "    def __get_bbox_data(self, prediction, threshold):\n",
    "        response = []\n",
    "        boxes = prediction[\"instances\"].pred_boxes\n",
    "        scores = prediction[\"instances\"].scores\n",
    "        for idx, entry in enumerate(boxes):\n",
    "          if scores[idx] >= threshold:\n",
    "            entry = entry.detach().to(\"cpu\").numpy()\n",
    "            x0, y0, x1, y1 = entry\n",
    "            response.append((x0, y0, x1, y1, scores[idx].item()))\n",
    "        return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tknLtWraNLVP",
    "outputId": "a9f9ccaa-694e-4596-9bfe-f0acbed17ddd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09/25 15:44:11 d2.checkpoint.detection_checkpoint]: [DetectionCheckpointer] Loading from /content/gdrive/MyDrive/magisterka/models/clear_faster.pth ...\n"
     ]
    }
   ],
   "source": [
    "model_detectron = Detectron2Model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JegYhWjXQ3r7"
   },
   "source": [
    "# MEAN AVERAGE PRECISION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wsdU2VnTQ21X"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "def intersection_over_union(boxes_preds, boxes_labels):\n",
    "    box1_x1 = boxes_preds[0:1]\n",
    "    box1_y1 = boxes_preds[1:2]\n",
    "    box1_x2 = boxes_preds[2:3]\n",
    "    box1_y2 = boxes_preds[3:4]\n",
    "    box2_x1 = boxes_labels[0:1]\n",
    "    box2_y1 = boxes_labels[1:2]\n",
    "    box2_x2 = boxes_labels[2:3]\n",
    "    box2_y2 = boxes_labels[3:4]\n",
    "\n",
    "    x1 = torch.max(box1_x1, box2_x1)\n",
    "    y1 = torch.max(box1_y1, box2_y1)\n",
    "    x2 = torch.min(box1_x2, box2_x2)\n",
    "    y2 = torch.min(box1_y2, box2_y2)\n",
    "\n",
    "    # Need clamp(0) in case they do not intersect, then we want intersection to be 0\n",
    "    intersection = (x2 - x1).clamp(0) * (y2 - y1).clamp(0)\n",
    "    box1_area = abs((box1_x2 - box1_x1) * (box1_y2 - box1_y1))\n",
    "    box2_area = abs((box2_x2 - box2_x1) * (box2_y2 - box2_y1))\n",
    "\n",
    "    return intersection / (box1_area + box2_area - intersection + 1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c4Hcz0_moYX3"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from collections import Counter\n",
    "\n",
    "def mean_average_precision(\n",
    "    pred_boxes, true_boxes, iou_threshold=0.5\n",
    "):\n",
    "\n",
    "    # Adapted from https://github.com/aladdinpersson/Machine-Learning-Collection/blob/master/ML/Pytorch/object_detection/metrics/mean_avg_precision.py\n",
    "    # list storing all AP for respective classes\n",
    "    average_precisions = []\n",
    "\n",
    "    # used for numerical stability later on\n",
    "    epsilon = 1e-6\n",
    "\n",
    "    detections = list(pred_boxes)\n",
    "    ground_truths = list(true_boxes)\n",
    "\n",
    "    # sort by box probabilities which is index 2\n",
    "    detections.sort(key=lambda x: x[4], reverse=True)\n",
    "    TP = torch.zeros((len(detections)))\n",
    "    FP = torch.zeros((len(detections)))\n",
    "    total_true_bboxes = len(ground_truths)\n",
    "\n",
    "    for detection_idx, detection in enumerate(detections):\n",
    "        ground_truth_img = [\n",
    "            bbox for bbox in ground_truths\n",
    "        ]\n",
    "\n",
    "        num_gts = len(ground_truth_img)\n",
    "        best_iou = 0\n",
    "\n",
    "        for idx, gt in enumerate(ground_truth_img):\n",
    "            iou = intersection_over_union(\n",
    "                torch.tensor(detection),\n",
    "                torch.tensor(gt)\n",
    "            )\n",
    "\n",
    "            if iou > best_iou:\n",
    "                best_iou = iou\n",
    "                best_gt_idx = idx\n",
    "\n",
    "        if best_iou > iou_threshold:\n",
    "            TP[detection_idx] = 1\n",
    "        # if IOU is lower then the detection is a false positive\n",
    "        else:\n",
    "            FP[detection_idx] = 1\n",
    "    TP_cumsum = torch.cumsum(TP, dim=0)\n",
    "    FP_cumsum = torch.cumsum(FP, dim=0)\n",
    "    recalls = TP_cumsum / (total_true_bboxes + epsilon)\n",
    "    precisions = TP_cumsum / (TP_cumsum + FP_cumsum + epsilon)\n",
    "    precisions = torch.cat((torch.tensor([1]), precisions))\n",
    "    recalls = torch.cat((torch.tensor([0]), recalls))\n",
    "    # torch.trapz for numerical integration\n",
    "    average_precisions.append(torch.trapz(precisions, recalls))\n",
    "    return (sum(average_precisions) / len(average_precisions)).item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Pwjm7_XcUUMh"
   },
   "source": [
    "# Prev sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3lzsC3OmUUol"
   },
   "outputs": [],
   "source": [
    "# Model evaluation - mean (IOS,precisions,recalls,f1_scores)  over images\n",
    "THRESHOLD = 0.7\n",
    "\n",
    "def model_evaluate(model,# Model instance\n",
    "                   threshold,# list of thresholds to be validated\n",
    "                   dataset_path,# dataset absolute path\n",
    "                   image_data,# list of images (annotations need to be read from .json by image name)\n",
    "                   data_annotation,\n",
    "                   net_type=\"detectron2\"):# name of annotations json\n",
    "\n",
    "    def average(entries):\n",
    "      return sum(entries) / len(entries)\n",
    "\n",
    "    #json_annotation_file = os.path.join(dataset_path, data_annotation)\n",
    "    json_annotation_file = data_annotation\n",
    "    #\n",
    "    ious = []\n",
    "    precisions = []\n",
    "    recalls = []\n",
    "    f1_scores = []\n",
    "    #\n",
    "    for image in image_data:\n",
    "      image_absolute_path = os.path.join(dataset_path, image)\n",
    "      if net_type == \"detectron2\":\n",
    "        opencv_image = cv2.imread(image_absolute_path)\n",
    "        prediction = model.predict(opencv_image, threshold = threshold)\n",
    "      ref_bbox = load_bbox_data(json_annotation_file, image)\n",
    "      iou_over_image, precision_over_image, recall_over_image, f1_over_image = calculate_metrics(ref_bbox, prediction)\n",
    "      ious.append(iou_over_image)\n",
    "      precisions.append(precision_over_image)\n",
    "      recalls.append(recall_over_image)\n",
    "      f1_scores.append(f1_over_image)\n",
    "\n",
    "    return average(ious), average(precisions), average(recalls), average(f1_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "haTfIqWQoUvJ"
   },
   "source": [
    "# TEST MEAN AVERAGE PRECISION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0sF0Lp2JzrBY"
   },
   "outputs": [],
   "source": [
    "def calculate_mAP_over_dataset(predictions, original_bboxs, iou_threshold = 0.5):\n",
    "  # predictions -> list of predictions over dataset\n",
    "  # original_bboxs -> list of original annotations for every image\n",
    "  # threshold -> threshold for iou\n",
    "  if len(predictions) != len(original_bboxs):\n",
    "    raise Exception(\"Prediction and original annotations mismatch\")\n",
    "  mAPs = []\n",
    "  for idx, pred in enumerate(predictions):\n",
    "    ground_truth = original_bboxs[idx]\n",
    "    mAP_for_image = mean_average_precision(pred, ground_truth, iou_threshold = iou_threshold)\n",
    "    mAPs.append(mAP_for_image)\n",
    "  #return mAPs\n",
    "  return sum(mAPs) / len(mAPs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "plcjTczTUkan"
   },
   "source": [
    "# Metrics eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IR6EZ2Jplz9Z"
   },
   "outputs": [],
   "source": [
    "IMAGE_PATH = os.path.join(DRIVE_PATH, \"test_images\")\n",
    "#IMAGE_RAW_PATH=os.path.join(DRIVE_PATH, \"dataset\")\n",
    "ANNOTATIONS_PATH = os.path.join(IMAGE_PATH, \"_annotations.coco.json\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C7_-mF1PYB0p"
   },
   "outputs": [],
   "source": [
    "image_names = [image for image in os.listdir(IMAGE_PATH) if \"json\" not in image]\n",
    "image_paths = [os.path.join(IMAGE_PATH, image) for image in os.listdir(IMAGE_PATH) if \"json\" not in image]\n",
    "annotations_file = ANNOTATIONS_PATH\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LASOUMcxUBge",
    "outputId": "53d970a8-c0b4-4118-baf3-1cedefec157a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mAP Detectron : 0.8095\n",
      "Mean IOUs over threshold : 0.7 -> 0.5946\n",
      "Mean prec over thresholds : 0.7-> 0.8276\n",
      "Mean recall over thresholds : 0.7 -> 0.7564\n",
      "Mean f1 over thresholds : 0.7 -> 0.7836\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# DETECTRON2\n",
    "detectron2_preds = []\n",
    "original_annotations = []\n",
    "\n",
    "for image_name in image_names:\n",
    "  bbox_data = load_bbox_data(annotations_file, image_name)\n",
    "  original_annotations.append(bbox_data)\n",
    "\n",
    "for image_path in image_paths:\n",
    "  image = cv2.imread(image_path)\n",
    "  prediction = model_detectron.predict(image, threshold=0.2)\n",
    "  detectron2_preds.append(prediction)\n",
    "\n",
    "\n",
    "detectron_mAPs = calculate_mAP_over_dataset(detectron2_preds, original_annotations, iou_threshold = 0.6)\n",
    "metrics_detectron = model_evaluate(model_detectron, PREDICTION_THRESHOLD_DETECTRON, IMAGE_PATH, image_names, annotations_file, net_type = \"detectron2\")\n",
    "\n",
    "#\n",
    "print(\"mAP Detectron : {:.4f}\".format(detectron_mAPs))\n",
    "print(f\"Mean IOUs over threshold : {PREDICTION_THRESHOLD_DETECTRON} ->\", \"{:.4f}\".format(metrics_detectron[0]))\n",
    "print(f\"Mean prec over thresholds : {PREDICTION_THRESHOLD_DETECTRON}->\", \"{:.4f}\".format(metrics_detectron[1]))\n",
    "print(f\"Mean recall over thresholds : {PREDICTION_THRESHOLD_DETECTRON} ->\", \"{:.4f}\".format(metrics_detectron[2]))\n",
    "print(f\"Mean f1 over thresholds : {PREDICTION_THRESHOLD_DETECTRON} ->\", \"{:.4f}\".format(metrics_detectron[3]))\n",
    "#\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y5x3kv2552d3"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
